{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5c4e47c6b9294f4d811d3304b49d5c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e63ca68de7774cc885c990d1372ec3a7",
              "IPY_MODEL_197e1cb05753409ab18965d9dce8671b",
              "IPY_MODEL_8493cfafb5c04f289f455cd122939343"
            ],
            "layout": "IPY_MODEL_6ec92ad788a84d4caa907ce3207d3154"
          }
        },
        "e63ca68de7774cc885c990d1372ec3a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0f8892f2cc64d2b9ebca726e9992a62",
            "placeholder": "​",
            "style": "IPY_MODEL_cd7d8292590942898acb41f42ca1a959",
            "value": "Map: 100%"
          }
        },
        "197e1cb05753409ab18965d9dce8671b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d4a4dff8a1f49e98962dbe7aefdce41",
            "max": 36473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d920595d4850437fba8281f1b238aa51",
            "value": 36473
          }
        },
        "8493cfafb5c04f289f455cd122939343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b3a3721260a4af0a98274682e0d1507",
            "placeholder": "​",
            "style": "IPY_MODEL_ef4664a0cbf04f039003205c50f1a34b",
            "value": " 36473/36473 [00:01&lt;00:00, 22366.91 examples/s]"
          }
        },
        "6ec92ad788a84d4caa907ce3207d3154": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0f8892f2cc64d2b9ebca726e9992a62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd7d8292590942898acb41f42ca1a959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d4a4dff8a1f49e98962dbe7aefdce41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d920595d4850437fba8281f1b238aa51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b3a3721260a4af0a98274682e0d1507": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef4664a0cbf04f039003205c50f1a34b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11328354f335475abf77fb4e64f3ed53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cdf2c1ae876a45ce880ffb81330a15b3",
              "IPY_MODEL_bf19b8c322e64d668197da6cac380410",
              "IPY_MODEL_e9a57e34ff1841749f7e07b6ba4ac46e"
            ],
            "layout": "IPY_MODEL_1670bdbd5c8d4f67ac7c0ff8565e0c93"
          }
        },
        "cdf2c1ae876a45ce880ffb81330a15b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef824319f81e43a483496b38ee5b6249",
            "placeholder": "​",
            "style": "IPY_MODEL_d6b56757264849f69666f587561639c4",
            "value": "Map: 100%"
          }
        },
        "bf19b8c322e64d668197da6cac380410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a08df292e3b42a7b7484ea08f86975a",
            "max": 36,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d52bdc909ed54b388d5f29a2c208d144",
            "value": 36
          }
        },
        "e9a57e34ff1841749f7e07b6ba4ac46e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b68e5a27b5d64fdfa03b095fe1917482",
            "placeholder": "​",
            "style": "IPY_MODEL_cf6cc1238f2144d19438114de14b7293",
            "value": " 36/36 [00:00&lt;00:00, 1106.99 examples/s]"
          }
        },
        "1670bdbd5c8d4f67ac7c0ff8565e0c93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef824319f81e43a483496b38ee5b6249": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6b56757264849f69666f587561639c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a08df292e3b42a7b7484ea08f86975a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d52bdc909ed54b388d5f29a2c208d144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b68e5a27b5d64fdfa03b095fe1917482": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf6cc1238f2144d19438114de14b7293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f7b83c6e31d4c49a15dbf045ef5ec49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c782bfd7052d4ac492974d77effb511f",
              "IPY_MODEL_db8a7f710b5d40fba07f22b5fda72916",
              "IPY_MODEL_ea90e2968c1346c0adc8fb8cc969d35f"
            ],
            "layout": "IPY_MODEL_b10792d62cfd4e44a9343b38e0cd81f5"
          }
        },
        "c782bfd7052d4ac492974d77effb511f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac44c23fc21e4aaaa0a6d1db62d7d14d",
            "placeholder": "​",
            "style": "IPY_MODEL_1d3b6fd1d4f7434198104f3f2981b95e",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "db8a7f710b5d40fba07f22b5fda72916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b6ac13e0401458690b34c884b66a1bf",
            "max": 286059269,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2456f0fd843c420ca356d8c615719ca9",
            "value": 286059269
          }
        },
        "ea90e2968c1346c0adc8fb8cc969d35f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bd98b589cbc41d9b072201820c32081",
            "placeholder": "​",
            "style": "IPY_MODEL_20b1e26aee424955849d087f466ebc9e",
            "value": " 286M/286M [00:01&lt;00:00, 233MB/s]"
          }
        },
        "b10792d62cfd4e44a9343b38e0cd81f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac44c23fc21e4aaaa0a6d1db62d7d14d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d3b6fd1d4f7434198104f3f2981b95e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b6ac13e0401458690b34c884b66a1bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2456f0fd843c420ca356d8c615719ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3bd98b589cbc41d9b072201820c32081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20b1e26aee424955849d087f466ebc9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3775f9091566489aaa32b948583fd8ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c90aadd76a354b0aa68250d46a004eef",
              "IPY_MODEL_9b46bdec42ef46c7af6822a73f41d412",
              "IPY_MODEL_ab745f69eb1e45039d45f4ee6afac177"
            ],
            "layout": "IPY_MODEL_e4af86707f8240de9a6b7fcf9c532c8d"
          }
        },
        "c90aadd76a354b0aa68250d46a004eef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5381b9cd30b4138818bde89ca02893a",
            "placeholder": "​",
            "style": "IPY_MODEL_7969f02f33b642599e57d33af9c9de6c",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "9b46bdec42ef46c7af6822a73f41d412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29e0d1cc5db94f8eb15499f79737e230",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa4a46aea114493694f5c93685a6319d",
            "value": 1
          }
        },
        "ab745f69eb1e45039d45f4ee6afac177": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50a4ad38df6b4790949b15397e0042cd",
            "placeholder": "​",
            "style": "IPY_MODEL_9e4860ced8fd4e508edf7c8fbb6bbba4",
            "value": " 1/1 [00:00&lt;00:00, 26.34ba/s]"
          }
        },
        "e4af86707f8240de9a6b7fcf9c532c8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5381b9cd30b4138818bde89ca02893a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7969f02f33b642599e57d33af9c9de6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29e0d1cc5db94f8eb15499f79737e230": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa4a46aea114493694f5c93685a6319d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50a4ad38df6b4790949b15397e0042cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e4860ced8fd4e508edf7c8fbb6bbba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e4cfe94090a401392ac23b26db2154d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca6471a4034f49e7b1c5ca60335f9bea",
              "IPY_MODEL_30519242a41b410f8e24f235fb7c8c37",
              "IPY_MODEL_09af5722d8024ae7ac9aa5267cfdcc1e"
            ],
            "layout": "IPY_MODEL_b7379d2a8a9e48e199bf3caf4dc1247e"
          }
        },
        "ca6471a4034f49e7b1c5ca60335f9bea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07ddce66c06a407590c40dbf148b8a4d",
            "placeholder": "​",
            "style": "IPY_MODEL_d7255ac0a3c245d3814b612248d4cfd6",
            "value": "Map: 100%"
          }
        },
        "30519242a41b410f8e24f235fb7c8c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25173a175ad14918a7353198af0903ee",
            "max": 36473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88194d8365d04292b338b5ef7a1d1ec3",
            "value": 36473
          }
        },
        "09af5722d8024ae7ac9aa5267cfdcc1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39816398d0be4b078b50d5976b6d6f12",
            "placeholder": "​",
            "style": "IPY_MODEL_9765c5a9e3694fc08457360766c7d117",
            "value": " 36473/36473 [00:01&lt;00:00, 21375.92 examples/s]"
          }
        },
        "b7379d2a8a9e48e199bf3caf4dc1247e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07ddce66c06a407590c40dbf148b8a4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7255ac0a3c245d3814b612248d4cfd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25173a175ad14918a7353198af0903ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88194d8365d04292b338b5ef7a1d1ec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39816398d0be4b078b50d5976b6d6f12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9765c5a9e3694fc08457360766c7d117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c909b5d5d2d4e919a32310dd2de8462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a38e4d5917534c65ad4ccc306fc29fc4",
              "IPY_MODEL_b19b3a6e8b02426eb961e1b534eb00b1",
              "IPY_MODEL_68766d729d154af5a5da8ba9a415113c"
            ],
            "layout": "IPY_MODEL_b0675bb5be584d58997725930883b597"
          }
        },
        "a38e4d5917534c65ad4ccc306fc29fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7b6a207fec54195b32be38965e4cc62",
            "placeholder": "​",
            "style": "IPY_MODEL_8711eb971e8c4a4e911a9114b95a6197",
            "value": "Map: 100%"
          }
        },
        "b19b3a6e8b02426eb961e1b534eb00b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fae0ef64628249a59a0eaad4747ee2c0",
            "max": 36473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2736f7203f5e4cdb84baf0452a367dad",
            "value": 36473
          }
        },
        "68766d729d154af5a5da8ba9a415113c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ebe062ebdca464f8135aff8319f2acc",
            "placeholder": "​",
            "style": "IPY_MODEL_714b1c18b7a14931af41b2ccbe101f8d",
            "value": " 36473/36473 [00:01&lt;00:00, 20033.03 examples/s]"
          }
        },
        "b0675bb5be584d58997725930883b597": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7b6a207fec54195b32be38965e4cc62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8711eb971e8c4a4e911a9114b95a6197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fae0ef64628249a59a0eaad4747ee2c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2736f7203f5e4cdb84baf0452a367dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ebe062ebdca464f8135aff8319f2acc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "714b1c18b7a14931af41b2ccbe101f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transformers\n",
        "1. The first part of this notebook runs through the details of running a transformer model (Jeremy Howard's **[Kaggle page](https://www.kaggle.com/code/jhoward/iterate-like-a-grandmaster/)**.).\n",
        "\n",
        "2. Then, I use ChatGPT to describe the details of transformers and I annotate the code in detail.\n",
        "\n",
        "3. Finally, I include notes from Jay Alammar's **[Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)**.\n",
        "\n",
        "*I suggest opening this notebook in Colab or in Kaggle.*"
      ],
      "metadata": {
        "id": "G4RfBWnT7NJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1. Running a Transformer Model\n",
        "This is all Jeremy Howard's code."
      ],
      "metadata": {
        "id": "B4gUqKYYOeMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install kaggle\n",
        "# !pip install transformers\n",
        "# !pip install datasets\n",
        "# !pip install sentencepiece\n",
        "# !pip install transformers[torch]\n",
        "# !pip install --upgrade transformers\n",
        "# !pip install --upgrade torch\n",
        "# !pip install accelerate -U"
      ],
      "metadata": {
        "id": "N4uL7EKqqfXi"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import warnings,transformers,logging,torch\n",
        "from transformers import TrainingArguments,Trainer\n",
        "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
        "\n",
        "import datasets\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "\n",
        "# warnings\n",
        "warnings.simplefilter('ignore')\n",
        "logging.disable(logging.WARNING)\n",
        "\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "lsUVlV7Vqa5S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d0ce802f-421b-4104-e861-3d6eca32731a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data is from kaggle -- set up creds\n",
        "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
        "creds = '{\"username\":\"FILL IN\",\"key\":\"FILL IN\"}'\n",
        "cred_path = Path('~/.kaggle/kaggle.json').expanduser()\n",
        "\n",
        "if not cred_path.exists():\n",
        "  cred_path.parent.mkdir(exist_ok=True)\n",
        "  cred_path.write_text(creds)\n",
        "  cred_path.chmod(0o600)\n",
        "\n",
        "cred_path"
      ],
      "metadata": {
        "id": "RxaqrNF6AFd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5c1d320-f486-45fa-e91e-b6deeda2e006"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.kaggle/kaggle.json')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "jY-NXzQyBA1q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download"
      ],
      "metadata": {
        "id": "KbnJq3QSBXIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = Path('/content/us-patent-phrase-to-phrase-matching/')\n",
        "comp = 'us-patent-phrase-to-phrase-matching'\n",
        "\n",
        "from kaggle import api\n",
        "if not path.exists():\n",
        "  path.mkdir(parents=True)\n",
        "  api.competition_download_cli(comp, path=path)\n",
        "  shutil.unpack_archive(str(path/f'{comp}.zip'), str(path))\n",
        "\n",
        "!ls {path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MblN9w_OlaXp",
        "outputId": "214acc94-e501-4a44-d669-9787929afa41"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_submission.csv  test.csv  train.csv  us-patent-phrase-to-phrase-matching.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # if you're working in a kaggle notebook, download datasets\n",
        "# if iskaggle:\n",
        "#   path = Path('../input/us-patent-phrase-to-phrase-matching')\n",
        "#   ! pip install -q datasets"
      ],
      "metadata": {
        "id": "j3fZWS0EBE9r"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA"
      ],
      "metadata": {
        "id": "m6sYEq_DBYJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(path/'train.csv')\n",
        "print(df.shape)\n",
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "HgIXmd9pBTdA",
        "outputId": "0eb231e9-1c2d-460a-a28e-850ce56fb017"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(36473, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id     anchor                  target context  score\n",
              "0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50\n",
              "1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75\n",
              "2  36d72442aefd8232  abatement         active catalyst     A47   0.25"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db67efab-86ba-400f-8c85-672128514814\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>anchor</th>\n",
              "      <th>target</th>\n",
              "      <th>context</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37d61fd2272659b1</td>\n",
              "      <td>abatement</td>\n",
              "      <td>abatement of pollution</td>\n",
              "      <td>A47</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7b9652b17b68b7a4</td>\n",
              "      <td>abatement</td>\n",
              "      <td>act of abating</td>\n",
              "      <td>A47</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>36d72442aefd8232</td>\n",
              "      <td>abatement</td>\n",
              "      <td>active catalyst</td>\n",
              "      <td>A47</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db67efab-86ba-400f-8c85-672128514814')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-db67efab-86ba-400f-8c85-672128514814 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-db67efab-86ba-400f-8c85-672128514814');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-155812b3-fe44-48f9-9bb8-f30be07e0120\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-155812b3-fe44-48f9-9bb8-f30be07e0120')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-155812b3-fe44-48f9-9bb8-f30be07e0120 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(include='object')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "hYOnLRqLBegG",
        "outputId": "ea746517-0413-43e0-bab5-1bf87a896f00"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      id                       anchor       target context\n",
              "count              36473                        36473        36473   36473\n",
              "unique             36473                          733        29340     106\n",
              "top     37d61fd2272659b1  component composite coating  composition     H01\n",
              "freq                   1                          152           24    2186"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9187851d-9afe-4341-98dc-4540f619fda3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>anchor</th>\n",
              "      <th>target</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>36473</td>\n",
              "      <td>36473</td>\n",
              "      <td>36473</td>\n",
              "      <td>36473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>36473</td>\n",
              "      <td>733</td>\n",
              "      <td>29340</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>37d61fd2272659b1</td>\n",
              "      <td>component composite coating</td>\n",
              "      <td>composition</td>\n",
              "      <td>H01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>152</td>\n",
              "      <td>24</td>\n",
              "      <td>2186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9187851d-9afe-4341-98dc-4540f619fda3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9187851d-9afe-4341-98dc-4540f619fda3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9187851d-9afe-4341-98dc-4540f619fda3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-28b43f98-d42c-4701-aac6-2f28642b4f23\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-28b43f98-d42c-4701-aac6-2f28642b4f23')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-28b43f98-d42c-4701-aac6-2f28642b4f23 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# look at some cols\n",
        "df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQrsnrGiqFgj",
        "outputId": "9219ac79-2457-47ec-89b7-596e5bc3182e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "composition                    24\n",
              "data                           22\n",
              "metal                          22\n",
              "motor                          22\n",
              "assembly                       21\n",
              "                               ..\n",
              "switching switch over valve     1\n",
              "switching switch off valve      1\n",
              "switching over valve            1\n",
              "switching off valve             1\n",
              "wooden substrate                1\n",
              "Name: target, Length: 29340, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# look at score (the DV)\n",
        "df.score.hist();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "YDBdVLQBqP4o",
        "outputId": "e0c1a261-c21c-463d-eed6-22c1a9641100"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess"
      ],
      "metadata": {
        "id": "qmBBGn1BEUPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download tokenizer"
      ],
      "metadata": {
        "id": "T55YMlJ2sGFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# choose model for tokenizer (tokenizer is model specific)\n",
        "model_name = 'microsoft/deberta-v3-small'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEaAbVrCDAtc",
        "outputId": "558ce78a-63dc-47a4-ba86-f7046be6eeb0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DebertaV2TokenizerFast(name_or_path='microsoft/deberta-v3-small', vocab_size=128000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
              "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t1: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t2: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t3: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
              "\t128000: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# start of a new word is represented by '▁'\n",
        "# uncommon word sare split into pieces\n",
        "tokenizer.tokenize(\"A platypus is an ornithorhynchus anatinus.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FImbsjGdEpOl",
        "outputId": "5ef2bc65-739f-45f5-c5cf-b8773058a9d0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁A',\n",
              " '▁platypus',\n",
              " '▁is',\n",
              " '▁an',\n",
              " '▁or',\n",
              " 'ni',\n",
              " 'tho',\n",
              " 'rhynch',\n",
              " 'us',\n",
              " '▁an',\n",
              " 'at',\n",
              " 'inus',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# look at the vocab (from the tokenizer) -- contains a unique integer for every possible token string\n",
        "print(tokenizer.vocab['▁is'])\n",
        "print(tokenizer.vocab['is'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWVEVSerFfLR",
        "outputId": "b37626d8-ca8f-4978-dcb1-6fb7800bc59f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "269\n",
            "1890\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# special tokens\n",
        "tokenizer.all_special_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdanXQxvwEiL",
        "outputId": "08265358-cb47-4c2e-d63e-68a52a61145d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]', '[SEP]', '[UNK]', '[PAD]', '[MASK]']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Combine multiple text columns together"
      ],
      "metadata": {
        "id": "-7ZAK-hssSm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sep = tokenizer.sep_token\n",
        "sep"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_TdqENe4rxw5",
        "outputId": "d8c11d86-d3f7-4e59-81df-997efbbb6954"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add a column that will be the input of the model\n",
        "df['inputs'] = df.context + sep + df.anchor + sep + df.target\n",
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "98NiyGB0r2CL",
        "outputId": "9eb79db2-ca7d-454b-b57b-e5a8d2c43332"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id     anchor                  target context  score  \\\n",
              "0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50   \n",
              "1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75   \n",
              "2  36d72442aefd8232  abatement         active catalyst     A47   0.25   \n",
              "\n",
              "                                         inputs  \n",
              "0  A47[SEP]abatement[SEP]abatement of pollution  \n",
              "1          A47[SEP]abatement[SEP]act of abating  \n",
              "2         A47[SEP]abatement[SEP]active catalyst  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c73d8500-2edc-448d-b5a2-f2bee7647820\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>anchor</th>\n",
              "      <th>target</th>\n",
              "      <th>context</th>\n",
              "      <th>score</th>\n",
              "      <th>inputs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37d61fd2272659b1</td>\n",
              "      <td>abatement</td>\n",
              "      <td>abatement of pollution</td>\n",
              "      <td>A47</td>\n",
              "      <td>0.50</td>\n",
              "      <td>A47[SEP]abatement[SEP]abatement of pollution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7b9652b17b68b7a4</td>\n",
              "      <td>abatement</td>\n",
              "      <td>act of abating</td>\n",
              "      <td>A47</td>\n",
              "      <td>0.75</td>\n",
              "      <td>A47[SEP]abatement[SEP]act of abating</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>36d72442aefd8232</td>\n",
              "      <td>abatement</td>\n",
              "      <td>active catalyst</td>\n",
              "      <td>A47</td>\n",
              "      <td>0.25</td>\n",
              "      <td>A47[SEP]abatement[SEP]active catalyst</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c73d8500-2edc-448d-b5a2-f2bee7647820')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c73d8500-2edc-448d-b5a2-f2bee7647820 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c73d8500-2edc-448d-b5a2-f2bee7647820');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ad0cf6bb-e744-4b7b-af3d-90903777d052\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ad0cf6bb-e744-4b7b-af3d-90903777d052')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ad0cf6bb-e744-4b7b-af3d-90903777d052 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# an alternative way to do this\n",
        "df['tmp'] = 'TEXT1: ' + df.context + '; TEXT2: ' + df.target + '; ANC1: ' + df.anchor\n",
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "OfwaAgSZBgSq",
        "outputId": "9fcd1b72-ebed-416a-9dd2-f2bcc3946145"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id     anchor                  target context  score  \\\n",
              "0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50   \n",
              "1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75   \n",
              "2  36d72442aefd8232  abatement         active catalyst     A47   0.25   \n",
              "\n",
              "                                         inputs  \\\n",
              "0  A47[SEP]abatement[SEP]abatement of pollution   \n",
              "1          A47[SEP]abatement[SEP]act of abating   \n",
              "2         A47[SEP]abatement[SEP]active catalyst   \n",
              "\n",
              "                                                 tmp  \n",
              "0  TEXT1: A47; TEXT2: abatement of pollution; ANC...  \n",
              "1  TEXT1: A47; TEXT2: act of abating; ANC1: abate...  \n",
              "2  TEXT1: A47; TEXT2: active catalyst; ANC1: abat...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68a7a96c-1ed6-435e-a19e-6f3cc230b6fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>anchor</th>\n",
              "      <th>target</th>\n",
              "      <th>context</th>\n",
              "      <th>score</th>\n",
              "      <th>inputs</th>\n",
              "      <th>tmp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37d61fd2272659b1</td>\n",
              "      <td>abatement</td>\n",
              "      <td>abatement of pollution</td>\n",
              "      <td>A47</td>\n",
              "      <td>0.50</td>\n",
              "      <td>A47[SEP]abatement[SEP]abatement of pollution</td>\n",
              "      <td>TEXT1: A47; TEXT2: abatement of pollution; ANC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7b9652b17b68b7a4</td>\n",
              "      <td>abatement</td>\n",
              "      <td>act of abating</td>\n",
              "      <td>A47</td>\n",
              "      <td>0.75</td>\n",
              "      <td>A47[SEP]abatement[SEP]act of abating</td>\n",
              "      <td>TEXT1: A47; TEXT2: act of abating; ANC1: abate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>36d72442aefd8232</td>\n",
              "      <td>abatement</td>\n",
              "      <td>active catalyst</td>\n",
              "      <td>A47</td>\n",
              "      <td>0.25</td>\n",
              "      <td>A47[SEP]abatement[SEP]active catalyst</td>\n",
              "      <td>TEXT1: A47; TEXT2: active catalyst; ANC1: abat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68a7a96c-1ed6-435e-a19e-6f3cc230b6fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-68a7a96c-1ed6-435e-a19e-6f3cc230b6fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-68a7a96c-1ed6-435e-a19e-6f3cc230b6fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-41854556-0760-44f8-ad80-8edfda7ca59b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-41854556-0760-44f8-ad80-8edfda7ca59b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-41854556-0760-44f8-ad80-8edfda7ca59b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create train/validation datasets"
      ],
      "metadata": {
        "id": "tQi77nEwuP-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transformers uses a dataset object\n",
        "ds = Dataset.from_pandas(df)\n",
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp9naFqTBrJU",
        "outputId": "bbdf6e39-e286-4fc2-c3d2-c83895a440a1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'anchor', 'target', 'context', 'score', 'inputs', 'tmp'],\n",
              "    num_rows: 36473\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transforms always assumes the DV is \"labels\"\n",
        "ds = ds.rename_columns({'score':'labels'})\n",
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyMSVEzCEvXT",
        "outputId": "39f7bee5-57a7-4c41-9d49-fa563c2e7f84"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'anchor', 'target', 'context', 'labels', 'inputs', 'tmp'],\n",
              "    num_rows: 36473\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenize data"
      ],
      "metadata": {
        "id": "ZX7UfswqsXmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tok_func(x):\n",
        "  \"\"\"\n",
        "  Tokenize the inputs\n",
        "  \"\"\"\n",
        "  tokenized = tokenizer(x[\"inputs\"])\n",
        "  return tokenized"
      ],
      "metadata": {
        "id": "mMAmJ5-LEvgr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize a single input\n",
        "# we only care about input_ids right now\n",
        "tok_func(ds[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ7qTuaou5NZ",
        "outputId": "a3e1921b-4a55-453c-da87-e90a6d67ee30"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [1, 336, 5753, 2, 47284, 2, 47284, 265, 6435, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize every row in the dataset -- adds a new item to ds called \"input_ids\"\n",
        "# also, remove columns you don't need\n",
        "inps = \"anchor\",\"target\",\"context\",\"id\"\n",
        "tok_ds = ds.map(tok_func, batched=True, remove_columns=inps) # map makes it run in parallel\n",
        "tok_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "5c4e47c6b9294f4d811d3304b49d5c9e",
            "e63ca68de7774cc885c990d1372ec3a7",
            "197e1cb05753409ab18965d9dce8671b",
            "8493cfafb5c04f289f455cd122939343",
            "6ec92ad788a84d4caa907ce3207d3154",
            "d0f8892f2cc64d2b9ebca726e9992a62",
            "cd7d8292590942898acb41f42ca1a959",
            "6d4a4dff8a1f49e98962dbe7aefdce41",
            "d920595d4850437fba8281f1b238aa51",
            "4b3a3721260a4af0a98274682e0d1507",
            "ef4664a0cbf04f039003205c50f1a34b"
          ]
        },
        "id": "53Ll9vMuEvel",
        "outputId": "161cc3cb-425a-4742-fb65-add9fb7f5998"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/36473 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c4e47c6b9294f4d811d3304b49d5c9e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['labels', 'inputs', 'tmp', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "    num_rows: 36473\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# single item of the ds\n",
        "item = tok_ds[0]\n",
        "item"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmAfyGsTwraL",
        "outputId": "13ab9bb0-2121-46ba-b466-270600bec353"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': 0.5,\n",
              " 'inputs': 'A47[SEP]abatement[SEP]abatement of pollution',\n",
              " 'tmp': 'TEXT1: A47; TEXT2: abatement of pollution; ANC1: abatement',\n",
              " 'input_ids': [1, 336, 5753, 2, 47284, 2, 47284, 265, 6435, 2],\n",
              " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create validation set"
      ],
      "metadata": {
        "id": "MhFAKwsjsd5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly shuffle anchors\n",
        "anchors = df.anchor.unique()\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(anchors)\n",
        "anchors[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhX7tem5xQBt",
        "outputId": "a34eef1b-686d-426b-c9f7-86eecf1706a9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['time digital signal', 'antiatherosclerotic', 'filled interior',\n",
              "       'dispersed powder', 'locking formation'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pick a proportion of anchors to go in the validation set\n",
        "val_prop = 0.25\n",
        "val_sz = int(len(anchors)*val_prop)\n",
        "val_anchors = anchors[:val_sz]\n",
        "val_anchors[:10]"
      ],
      "metadata": {
        "id": "sq96xW0Zxc5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9c99233-7aa0-49c0-d716-0f7dc1e07b09"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['time digital signal', 'antiatherosclerotic', 'filled interior',\n",
              "       'dispersed powder', 'locking formation', 'container opener',\n",
              "       'apply to anode electrode', 'pen based computer', 'running tally',\n",
              "       'maleic anhydride grafted'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get a list of which rows match val_anchors, and get their indices\n",
        "is_val = np.isin(df.anchor, val_anchors)\n",
        "idxs = np.arange(len(df))\n",
        "val_idxs = idxs[ is_val]\n",
        "trn_idxs = idxs[~is_val]\n",
        "len(val_idxs),len(trn_idxs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XVZj_a6xmB4",
        "outputId": "56962a0c-5b99-4ee4-e9de-2c090d6d7470"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9116, 27357)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare means\n",
        "df.iloc[trn_idxs].score.mean(),df.iloc[val_idxs].score.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTaiT8DmybuT",
        "outputId": "a60fcf1d-4fbc-48f9-bc5a-e85653ba06da"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3623021530138539, 0.3613426941641071)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformers uses a `DatasetDict` for holding your training and validation sets\n",
        "# note: the validation set in this dds needs to be called \"test set\", which is annoying\n",
        "dds = DatasetDict({\n",
        "  \"train\":tok_ds.select(trn_idxs),\n",
        "  \"test\": tok_ds.select(val_idxs)\n",
        "})\n",
        "dds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGN_utngx0mM",
        "outputId": "26976f3a-a4d3-4109-d2a8-b3ca256297a2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['labels', 'inputs', 'tmp', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 27357\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['labels', 'inputs', 'tmp', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 9116\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# easier way to do this\n",
        "dds = tok_ds.train_test_split(0.25, seed=42)\n",
        "dds"
      ],
      "metadata": {
        "id": "q6oWzxMSnOQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "529a813f-f472-42b3-8cdd-66898cced73c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['labels', 'inputs', 'tmp', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 27354\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['labels', 'inputs', 'tmp', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 9119\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create test set"
      ],
      "metadata": {
        "id": "fu3c8IEByTA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test set\n",
        "eval_df = pd.read_csv(path/'test.csv')\n",
        "eval_df['inputs'] = eval_df.context + sep + eval_df.anchor + sep + eval_df.target\n",
        "eval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)\n",
        "eval_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "11328354f335475abf77fb4e64f3ed53",
            "cdf2c1ae876a45ce880ffb81330a15b3",
            "bf19b8c322e64d668197da6cac380410",
            "e9a57e34ff1841749f7e07b6ba4ac46e",
            "1670bdbd5c8d4f67ac7c0ff8565e0c93",
            "ef824319f81e43a483496b38ee5b6249",
            "d6b56757264849f69666f587561639c4",
            "9a08df292e3b42a7b7484ea08f86975a",
            "d52bdc909ed54b388d5f29a2c208d144",
            "b68e5a27b5d64fdfa03b095fe1917482",
            "cf6cc1238f2144d19438114de14b7293"
          ]
        },
        "id": "QwVWI1eiyUVB",
        "outputId": "b3a19784-a86a-411d-e1b4-d111fd359ad6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/36 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11328354f335475abf77fb4e64f3ed53"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'anchor', 'target', 'context', 'inputs', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "    num_rows: 36\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train transformers model\n",
        "- Transformers works well with \"sequence-to-sequence\" problems (where the dependent variable is itself a variable-length sequence, such as language translation)\n",
        "- They are also very good at capturing long-range dependencies and reltationships in data\n",
        "- Here, we are first just running through all of the code to get a big picture\n"
      ],
      "metadata": {
        "id": "hIgZTvxMoo-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation metric -- correlation"
      ],
      "metadata": {
        "id": "akOQ41GPymbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to return a dictionary since that's how Transformers know what label to use\n",
        "def corr(eval_pred):\n",
        "  return{'pearson': np.corrcoef(*eval_pred)[0][1]}"
      ],
      "metadata": {
        "id": "HhvVmAFhnK8k"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparams\n",
        "bs = 128\n",
        "epochs = 4\n",
        "lr = 8e-5\n",
        "wd = 0.01"
      ],
      "metadata": {
        "id": "3HV_Nl-VorZI"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformers use the TrainingArguments class to set up arguments\n",
        "# needs to be run on a gpu\n",
        "args = TrainingArguments(\n",
        "  'outputs',\n",
        "  learning_rate=lr,\n",
        "  warmup_ratio=0.1,\n",
        "  lr_scheduler_type='cosine',  # cosine scheduler (with warmup)\n",
        "  fp16=True,\n",
        "  evaluation_strategy=\"epoch\",\n",
        "  per_device_train_batch_size=bs,\n",
        "  per_device_eval_batch_size=bs*2, # evaluate using double-sized batches, since no gradients are stored so we can do twice as many rows at a time\n",
        "  num_train_epochs=epochs,\n",
        "  weight_decay=wd,\n",
        "  report_to='none'\n",
        ")\n",
        "# args"
      ],
      "metadata": {
        "id": "zkFs54Asosxw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# crate model\n",
        "# recall, model name was specified earlier -- used for tokenization\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871,
          "referenced_widgets": [
            "7f7b83c6e31d4c49a15dbf045ef5ec49",
            "c782bfd7052d4ac492974d77effb511f",
            "db8a7f710b5d40fba07f22b5fda72916",
            "ea90e2968c1346c0adc8fb8cc969d35f",
            "b10792d62cfd4e44a9343b38e0cd81f5",
            "ac44c23fc21e4aaaa0a6d1db62d7d14d",
            "1d3b6fd1d4f7434198104f3f2981b95e",
            "7b6ac13e0401458690b34c884b66a1bf",
            "2456f0fd843c420ca356d8c615719ca9",
            "3bd98b589cbc41d9b072201820c32081",
            "20b1e26aee424955849d087f466ebc9e"
          ]
        },
        "id": "qu62qX95o4UF",
        "outputId": "ac3b5108-6de1-4ef7-b9c1-18da3442e190"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/286M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f7b83c6e31d4c49a15dbf045ef5ec49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DebertaV2ForSequenceClassification(\n",
              "  (deberta): DebertaV2Model(\n",
              "    (embeddings): DebertaV2Embeddings(\n",
              "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "      (dropout): StableDropout()\n",
              "    )\n",
              "    (encoder): DebertaV2Encoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (rel_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (pooler): ContextPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): StableDropout()\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (dropout): StableDropout()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create trainer (class that combines the data and model together)\n",
        "# like learner in fastai\n",
        "trainer = Trainer(\n",
        "  model,\n",
        "  args,\n",
        "  train_dataset=dds['train'],\n",
        "  eval_dataset=dds['test'], # validation set\n",
        "  tokenizer=tokenizer, # defined above\n",
        "  compute_metrics=corr # we defined this above\n",
        ")\n",
        "trainer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8G3244CpLuC",
        "outputId": "503a81d4-82f5-4223-b3e6-7a0de3709bc7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<transformers.trainer.Trainer at 0x7b032b259120>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "# look for pearson correlation (our evaluation metric)\n",
        "trainer.train();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "QFfKsDSppLr9",
        "outputId": "cb91254e-4c69-44bc-ecf2-b06cff32d457"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='856' max='856' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [856/856 03:04, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Pearson</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.030799</td>\n",
              "      <td>0.794244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.022934</td>\n",
              "      <td>0.814307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.043000</td>\n",
              "      <td>0.022468</td>\n",
              "      <td>0.828692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.043000</td>\n",
              "      <td>0.022996</td>\n",
              "      <td>0.829272</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get preds\n",
        "preds = trainer.predict(eval_ds).predictions.astype(float)\n",
        "\n",
        "# fix out of bounds predictions (<0 or >1)\n",
        "preds = np.clip(preds, 0, 1)\n",
        "preds[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "NR2aTR9epLpn",
        "outputId": "58a0f0e1-adce-419d-85ac-920d8850a946"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.57763672],\n",
              "       [0.62646484],\n",
              "       [0.51757812],\n",
              "       [0.31787109],\n",
              "       [0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save\n",
        "submission = datasets.Dataset.from_dict({\n",
        "  'id': eval_ds['id'],\n",
        "  'score': preds\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "7QXtz2txpLnA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "3775f9091566489aaa32b948583fd8ea",
            "c90aadd76a354b0aa68250d46a004eef",
            "9b46bdec42ef46c7af6822a73f41d412",
            "ab745f69eb1e45039d45f4ee6afac177",
            "e4af86707f8240de9a6b7fcf9c532c8d",
            "c5381b9cd30b4138818bde89ca02893a",
            "7969f02f33b642599e57d33af9c9de6c",
            "29e0d1cc5db94f8eb15499f79737e230",
            "aa4a46aea114493694f5c93685a6319d",
            "50a4ad38df6b4790949b15397e0042cd",
            "9e4860ced8fd4e508edf7c8fbb6bbba4"
          ]
        },
        "outputId": "e251c28d-e022-42cf-9be7-13cf2196aaf6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3775f9091566489aaa32b948583fd8ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1025"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iterate\n",
        "- Need to know whether the model gives stable results (e.g., try training it 3 times from scratch)\n",
        "- Later on, if and when we feel confident that we've got the basics right, we can use cross validation and more epochs of training."
      ],
      "metadata": {
        "id": "mO91LsdQ2EE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to apply tokenization and create the dataset dict\n",
        "# note -- requires the train/valid indices we created by hand earlier\n",
        "def get_dds(df):\n",
        "  ds = Dataset.from_pandas(df).rename_column('score', 'label')\n",
        "  tok_ds = ds.map(\n",
        "    tok_func,\n",
        "    batched=True,\n",
        "    remove_columns=inps+('inputs','id')\n",
        "  )\n",
        "\n",
        "  dds = DatasetDict({\n",
        "    \"train\":tok_ds.select(trn_idxs),\n",
        "    \"test\": tok_ds.select(val_idxs)\n",
        "  })\n",
        "  return dds"
      ],
      "metadata": {
        "id": "1qSWzxSB2USD"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to create a trainer\n",
        "def get_model():\n",
        "  return AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n",
        "\n",
        "def get_trainer(dds, model=None):\n",
        "  if model is None:\n",
        "    model = get_model()\n",
        "\n",
        "  args = TrainingArguments(\n",
        "    'outputs',\n",
        "    learning_rate=lr,\n",
        "    warmup_ratio=0.1,\n",
        "    lr_scheduler_type='cosine',\n",
        "    fp16=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=bs,\n",
        "    per_device_eval_batch_size=bs*2,\n",
        "    num_train_epochs=epochs,\n",
        "    weight_decay=wd,\n",
        "    report_to='none'\n",
        "  )\n",
        "\n",
        "  trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=dds['train'],\n",
        "    eval_dataset=dds['test'],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=corr\n",
        "  )\n",
        "  return trainer"
      ],
      "metadata": {
        "id": "v2FWaTzB2auC"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Try a different separater"
      ],
      "metadata": {
        "id": "B4veQx543Ocv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sep = \" [s] \"\n",
        "df['inputs'] = df.context + sep + df.anchor + sep + df.target\n",
        "\n",
        "dds = get_dds(df)\n",
        "get_trainer(dds).train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286,
          "referenced_widgets": [
            "4e4cfe94090a401392ac23b26db2154d",
            "ca6471a4034f49e7b1c5ca60335f9bea",
            "30519242a41b410f8e24f235fb7c8c37",
            "09af5722d8024ae7ac9aa5267cfdcc1e",
            "b7379d2a8a9e48e199bf3caf4dc1247e",
            "07ddce66c06a407590c40dbf148b8a4d",
            "d7255ac0a3c245d3814b612248d4cfd6",
            "25173a175ad14918a7353198af0903ee",
            "88194d8365d04292b338b5ef7a1d1ec3",
            "39816398d0be4b078b50d5976b6d6f12",
            "9765c5a9e3694fc08457360766c7d117"
          ]
        },
        "id": "Ctd46qFe3Hqt",
        "outputId": "d1e003f1-1e9a-489a-f7df-6023cce7c30b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/36473 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e4cfe94090a401392ac23b26db2154d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='856' max='856' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [856/856 03:12, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Pearson</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.024950</td>\n",
              "      <td>0.801454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.026331</td>\n",
              "      <td>0.815467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.029700</td>\n",
              "      <td>0.023691</td>\n",
              "      <td>0.818883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.029700</td>\n",
              "      <td>0.024160</td>\n",
              "      <td>0.819522</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=856, training_loss=0.02278392504308825, metrics={'train_runtime': 192.8065, 'train_samples_per_second': 567.553, 'train_steps_per_second': 4.44, 'total_flos': 582121520370810.0, 'train_loss': 0.02278392504308825, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Try lowercase"
      ],
      "metadata": {
        "id": "NhGSGPQ83mNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['inputs'] = df.inputs.str.lower()\n",
        "dds = get_dds(df)\n",
        "get_trainer(dds).train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286,
          "referenced_widgets": [
            "6c909b5d5d2d4e919a32310dd2de8462",
            "a38e4d5917534c65ad4ccc306fc29fc4",
            "b19b3a6e8b02426eb961e1b534eb00b1",
            "68766d729d154af5a5da8ba9a415113c",
            "b0675bb5be584d58997725930883b597",
            "a7b6a207fec54195b32be38965e4cc62",
            "8711eb971e8c4a4e911a9114b95a6197",
            "fae0ef64628249a59a0eaad4747ee2c0",
            "2736f7203f5e4cdb84baf0452a367dad",
            "4ebe062ebdca464f8135aff8319f2acc",
            "714b1c18b7a14931af41b2ccbe101f8d"
          ]
        },
        "id": "MhUOwFDp3Xgn",
        "outputId": "1b1bec86-5baa-4490-eec6-879344ece23f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/36473 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c909b5d5d2d4e919a32310dd2de8462"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='856' max='856' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [856/856 03:14, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Pearson</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.026600</td>\n",
              "      <td>0.796815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.026546</td>\n",
              "      <td>0.817279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.031300</td>\n",
              "      <td>0.023419</td>\n",
              "      <td>0.817951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.031300</td>\n",
              "      <td>0.024410</td>\n",
              "      <td>0.818169</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=856, training_loss=0.023865558833719415, metrics={'train_runtime': 194.9328, 'train_samples_per_second': 561.363, 'train_steps_per_second': 4.391, 'total_flos': 582121520370810.0, 'train_loss': 0.023865558833719415, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Make the patent section a special token\n",
        "So that different sections need to be handled in different ways\n",
        "\n",
        "**_Note_: `section` isn't in the df. not sure why. I've commented this section out because we can't run it, but kept it in here for reference for other projects**"
      ],
      "metadata": {
        "id": "cC8znN_K3rZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # turn patent sections into special tokens (e.g., Section A --> [A])\n",
        "# df['sectok'] = '[' + df.section + ']'\n",
        "# sectoks = list(df.sectok.unique())\n",
        "# tokenizer.add_special_tokens({'additional_special_tokens': sectoks})"
      ],
      "metadata": {
        "id": "Guf30B9g35Sq"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # add the section token to the start of the inputs\n",
        "# df['inputs'] = df.sectok + sep + df.context + sep + df.anchor.str.lower() + sep + df.target\n",
        "# dds = get_dds(df)"
      ],
      "metadata": {
        "id": "nYoCfpTA4ENk"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Since we've added more tokens, we need to resize the embedding matrix in the model\n",
        "# model = get_model()\n",
        "# model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "id": "Om59mpxc4Jiz"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # train\n",
        "# trainer = get_trainer(dds, model=model)\n",
        "# trainer.train()"
      ],
      "metadata": {
        "id": "aKv8anjI4OAp"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross-validation\n",
        "- 4 folds = 4 models and 4 sets of predictions and metrics\n",
        "- can ensemble the 4 models to get a stronger model\n",
        "- can also average the 4 metrics to get a more accurate assessment of your model"
      ],
      "metadata": {
        "id": "u9Y6jpoW4EAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "\n",
        "n_folds = 4\n",
        "cv = StratifiedGroupKFold(n_splits=n_folds)"
      ],
      "metadata": {
        "id": "KmEhPBjj4V-q"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# randomly shuffle the rows\n",
        "df = df.sample(frac=1, random_state=42)"
      ],
      "metadata": {
        "id": "QCB8xUvg4huJ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data frame into n_folds groups, with non-overlapping anchors and matched scores\n",
        "scores = (df.score*100).astype(int)\n",
        "folds = list(cv.split(idxs, scores, df.anchor))\n",
        "folds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA8Fuzcy4dGD",
        "outputId": "45549ae5-1f66-459f-ba4b-fae72ade7332"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([    0,     1,     2, ..., 36469, 36471, 36472]),\n",
              "  array([    8,    13,    14, ..., 36453, 36464, 36470])),\n",
              " (array([    0,     1,     5, ..., 36470, 36471, 36472]),\n",
              "  array([    2,     3,     4, ..., 36459, 36461, 36462])),\n",
              " (array([    1,     2,     3, ..., 36467, 36470, 36472]),\n",
              "  array([    0,     7,    11, ..., 36468, 36469, 36471])),\n",
              " (array([    0,     2,     3, ..., 36469, 36470, 36471]),\n",
              "  array([    1,     5,     9, ..., 36465, 36467, 36472]))]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split into train/valid sets based on a fold\n",
        "def get_fold(folds, fold_num):\n",
        "  trn,val = folds[fold_num]\n",
        "  return DatasetDict({\"train\":tok_ds.select(trn), \"test\": tok_ds.select(val)})"
      ],
      "metadata": {
        "id": "CSbkqM_w4tIX"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get dds\n",
        "dds = get_fold(folds, 0)\n",
        "dds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4pmgpTf4y6y",
        "outputId": "fee99ec7-c917-4ef4-c329-f97fc33f742c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['labels', 'inputs', 'tmp', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 27346\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['labels', 'inputs', 'tmp', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 9127\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the final epoch metrics from a trainer\n",
        "metrics = [o['eval_pearson'] for o in trainer.state.log_history if 'eval_pearson' in o]\n",
        "print(metrics)\n",
        "\n",
        "# final metric\n",
        "metrics[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_-p06Oe42S8",
        "outputId": "a4e1f7b1-f9fb-47a2-cf85-01d157bebcb3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7942444538888033, 0.8143074177887484, 0.8286924799565081, 0.8292720857935653]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8292720857935653"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2. ChatGPT's descriptions of transformers\n",
        "I've annotated the code in detail.\n",
        "\n",
        "**Note! There may be errors in the code because ChatGPT is NOT perfect!**"
      ],
      "metadata": {
        "id": "tp2ztQarNkK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Terminology\n",
        "- Attention Head\n",
        "  - An \"attention head\" refers to an individual stream or pathway through which the model processes information\n",
        "  - Each attention head independently learns different relationships and patterns within the input sequence.\n",
        "  - By having multiple attention heads, the model can capture diverse features and relationships simultaneously.\n",
        "  - For each attention head, the input embeddings are linearly transformed into three sets of vectors: queries, keys, and values. These vectors play distinct roles in the self-attention mechanism\n",
        "- Query\n",
        "  - The query is a linear transformation applied to the input embeddings to create a set of query vectors.\n",
        "  - These query vectors are used to determine how much attention each element in the sequence should pay to other elements.\n",
        "  - Queries represent the elements of the input sequence for which the model is trying to find relevant information or relationships.\n",
        "  - For each element in the input sequence, a corresponding query vector is created.\n",
        "  - Mathematically, if X is the input sequence, the query vectors Q are computed as Q = X * W_q, where W_q is a learnable weight matrix.\n",
        "- Key\n",
        "  - Similar to the query, the key is another linear transformation applied to the input embeddings to create a set of key vectors.\n",
        "  - These key vectors represent the elements that the query vectors will attend to.\n",
        "  - Keys represent the elements of the input sequence that provide context or information about other elements in the sequence.\n",
        "  - For each element in the input sequence, a corresponding key vector is created.\n",
        "  - Mathematically, if X is the input sequence, the key vectors K are computed as K = X * W_k, where W_k is a learnable weight matrix.\n",
        "- Value\n",
        "  - The value is a linear transformation applied to the input embeddings to create a set of value vectors.\n",
        "  0 These value vectors represent the information that will be combined based on the attention weights obtained from the query-key interactions.\n",
        "  - Values represent the actual information associated with each element in the input sequence.\n",
        "  - For each element in the input sequence, a corresponding value vector is created.\n",
        "  - Mathematically, if X is the input sequence, the value vectors V are computed as V = X * W_v, where W_v is a learnable weight matrix."
      ],
      "metadata": {
        "id": "oSFLN61QP2AZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Self-Attention Mechanism\n",
        "- The core of the transformer architecture is the self-attention mechanism. This mechanism allows the model to weigh the importance of different parts of the input sequence when processing each element. It lets the transformer model focus on (and amplify) the signal from the relevant parts of the input\n",
        "- For each element in the input sequence, attention scores are calculated with respect to all other elements. These scores determine how much focus should be given to each element during computation. should be given to each element during computation.\n",
        "- In the self-attention mechanism, the interactions between queries, keys, and values are computed using dot products. The attention scores are calculated by taking the dot product of queries with keys, and the weighted sum of values based on these attention scores provides the output of the attention mechanism.\n",
        "\n"
      ],
      "metadata": {
        "id": "3WRII1Z8pQcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "YDuJyWkSqkds"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(nn.Module):\n",
        "  def __init__(self, embed_size, heads):\n",
        "    super(SelfAttention, self).__init__()\n",
        "    self.embed_size = embed_size # dimensionality of the input embeddings (e.g., 256)\n",
        "    self.heads = heads # number of attention heads (e.g., 8)\n",
        "    self.head_dim = embed_size // heads # dimensionality of each attention head (e.g., 32: each attention head processes information in a 32 dimensional space)\n",
        "\n",
        "    assert ( # throws error if head_dim isn't an integer\n",
        "      self.head_dim * heads == embed_size\n",
        "    ), \"Embedding size needs to be divisible by heads\"\n",
        "\n",
        "    # Linear transformations for values, keys, and queries (involves learned weights)\n",
        "    self.values = nn.Linear(self.head_dim, self.head_dim, bias=False) # Provides the information associated with each element in the sequence\n",
        "    self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False) # Represents the elements to which the query vectors will attend\n",
        "    self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False) # Determines what to focus on in the input sequence\n",
        "\n",
        "    # Linear transformation for the output of self-attention\n",
        "    self.fc_out = nn.Linear(\n",
        "        heads * self.head_dim, # the combined size of the output vectors from all attention heads\n",
        "        embed_size # desired dimensionality of the output after the linear transformation\n",
        "      )\n",
        "\n",
        "  def forward(self, values, keys, query, mask):\n",
        "    # Get number of training examples\n",
        "    N = query.shape[0] # the number of the training samples in the batch\n",
        "\n",
        "    # Calculate the lengths of the sequences for v,k,q.\n",
        "    # Each sequence can have a different length\n",
        "    value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
        "\n",
        "    # Split the embedding into self.heads different pieces\n",
        "    # Reshaping is done to split the embedding vectors into different pieces corresponding to each attention head\n",
        "    values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
        "    keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
        "    queries = query.reshape(N, query_len, self.heads, self.head_dim)\n",
        "\n",
        "    # Linear transformations for values, keys, and queries (involves weights and biases)\n",
        "    # Project v,k,q into a new space with different dimensions\n",
        "    values = self.values(values) # self.values is actual an instance of nn.Linear\n",
        "    keys = self.keys(keys) # same as above: this is a linear transformation\n",
        "    queries = self.queries(queries) # same\n",
        "\n",
        "    # Calculate attention scores using the self-attention mechanism\n",
        "    # Attention scores = weights assigned to different positions in the input sequence (similarity between keys and values)\n",
        "    # Uses batched matrix multiplication and summation of queries and keys\n",
        "    # This is shown with Einstein summation notation, which specifies the dimensions and operations\n",
        "    # The resulting tensor (energy) has dimensions (N, heads, query_len, key_len)\n",
        "    energy = torch.einsum(\n",
        "      \"nqhd,nkhd->nhqk\",\n",
        "        # nqhd: shape of the queries tensor = (batch_size, query_len, heads, head_dim)\n",
        "        # nkhd: shape of the keys tensor = (batch_size, key_len, heads, head_dim)\n",
        "        # -> the operation to be performed (batched matrix multiplication and summation)\n",
        "        # nhqk: shape of the resulting tensor = (batch_size, heads, query_len, key_len)\n",
        "      [queries, keys]\n",
        "    )\n",
        "\n",
        "    # optional mask: used to zero out certain elements in the attention scores based on the mask's values\n",
        "    # If a mask is provided, use masked_fill to replace elements in the energy tensor\n",
        "    # with a large negative value (float(\"-1e20\")) where the corresponding mask value is 0\n",
        "    # By setting the attention scores to a large negative value, the softmax operation later\n",
        "    # in the process ensures that the attention weights for those positions become close to zero\n",
        "    if mask is not None:\n",
        "      energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
        "\n",
        "    # Apply softmax to obtain attention weights\n",
        "    # The attention scores calculated from the energy tensor are normalized using the softmax function\n",
        "    attention = torch.nn.functional.softmax(\n",
        "      energy / (self.embed_size ** (1 / 2)), # scales the energy tensor by the square root of the embedding size (stabilizes gradients)\n",
        "      dim=3 # apply softmax along the 4th dimension of the scaled energy tensor (the key sequence length)\n",
        "    )\n",
        "\n",
        "    # Apply attention weights to values and reshape\n",
        "    # Calculates attended values = result of applying attention scores to the values (linearly combined)\n",
        "    out = torch.einsum(\n",
        "      \"nhql,nlhd->nqhd\",\n",
        "        # nhql: shape of the attention tensor = (batch_size, heads, query_len, key_len)\n",
        "        # nlhd: shape of the values tensor = (batch_size, key_len, heads, head_dim)\n",
        "        # nqhd: shape of the resulting tensor = (batch_size, query_len, heads, head_dim)\n",
        "      [attention, values]\n",
        "    ).reshape(\n",
        "      N, query_len, self.heads * self.head_dim # combines the dimensions of the attention heads to (batch_size, query_len, heads * head_dim)\n",
        "    )\n",
        "\n",
        "    # Linear transformation for the output of self-attention\n",
        "    # Maps the output of the self-attention mechanism to a new space with a different dimensionality specified by embed_size\n",
        "    # final output shape: (batch_size, query_len, embed_size)\n",
        "    out = self.fc_out(out) # self.hc_out is an instance of the nn.Linear module\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "DBtAUDwfzMOQ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Head Attention\n",
        "- To enhance the model's ability to capture diverse patterns, transformers use multiple self-attention mechanisms in parallel, known as \"multi-head attention.\"\n",
        "- Each attention head learns different relationships and representations. The outputs from all attention heads are concatenated and linearly transformed to obtain the final attention output.\n",
        "- Note: it operates with multiple heads in parallel. Each head has its own set of learned parameters. At the end of the class, the outputs of the heads are concatenated."
      ],
      "metadata": {
        "id": "0DAqlhC6pclr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, embed_size, heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.embed_size = embed_size # embeddings dimensions\n",
        "    self.heads = heads # number of attention heads\n",
        "    self.head_dim = embed_size // heads # dimensionality of attention heads\n",
        "\n",
        "    assert (\n",
        "        self.head_dim * heads == embed_size\n",
        "    ), \"Embedding size needs to be divisible by heads\" # throw error if head_dim isn't an integer\n",
        "\n",
        "    # Instantiate self-attention mechanism (defined above) --> combination of attention scores and attended values\n",
        "    # SelfAttention created a single attention head\n",
        "    # Now we can use multiple instances of this block to create a multi-headed attention mechanism\n",
        "    self.attention = SelfAttention(embed_size, heads) # there are heads instances of SelfAttention, each with its own learned params\n",
        "\n",
        "    # Linear transformation for the output of multi-head attention\n",
        "    self.fc_out = nn.Linear(\n",
        "      heads * self.head_dim, # input size\n",
        "      embed_size # oupput size\n",
        "    )\n",
        "\n",
        "  def forward(self, values, keys, query, mask):\n",
        "    N = query.shape[0] # the number of the training samples in the batch\n",
        "    value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1] #  Calculate the lengths of the sequences for v,k,q\n",
        "\n",
        "    # Split the embedding into self.heads different pieces\n",
        "    values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
        "    keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
        "    queries = query.reshape(N, query_len, self.heads, self.head_dim)\n",
        "\n",
        "    # Transpose dimensions for compatibility with self-attention mechanism\n",
        "    values = values.permute(0, 2, 1, 3) # original dimensions: (batch_size, value_len, heads, head_dim); new dimensions: (batch_size, heads, value_len, head_dim)\n",
        "    keys = keys.permute(0, 2, 1, 3) # orig: (batch_size, key_len, heads, head_dim); new: (batch_size, heads, key_len, head_dim)\n",
        "    queries = queries.permute(0, 2, 1, 3) # orig: (batch_size, query_len, heads, head_dim); new: (batch_size, heads, query_len, head_dim)\n",
        "\n",
        "    # Apply multi-head attention mechanism to the input tensors v,k,q\n",
        "    attention = self.attention(values, keys, queries, mask) # attention dimensions: (batch_size, heads, query_len, key_len)\n",
        "\n",
        "    # Transpose dimensions back (contiguous has to do with the memory layout)\n",
        "    attention = attention.permute(0, 2, 1, 3).contiguous() # new attention dimensions: (batch_size, query_len, heads, key_len)\n",
        "\n",
        "    # Reshape to match the input dimensions\n",
        "    # concatenates the outputs of the individual attention heads\n",
        "    out = attention.reshape(N, query_len, self.heads * self.head_dim) # concatenates along the embedding dimension\n",
        "\n",
        "    # Linear transformation for the output of multi-head attention\n",
        "    return self.fc_out(out)"
      ],
      "metadata": {
        "id": "37FNjOBapfde"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Positional Encoding\n",
        "- Transformers don't have an inherent understanding of the order of elements in a sequence. To incorporate sequential information, positional encodings are added to the input embeddings.\n",
        "- Positional encodings are vectors that represent the position of each element in the sequence, allowing the model to distinguish between different positions.\n",
        "- Notes:\n",
        "  - The use of alternating columns (sine for even-indexed columns and cosine for odd-indexed columns) in the positional encoding helps introduce distinct patterns in the encoding for different positions along the sequence. This alternating pattern helps capture different frequencies of positional information.\n",
        "  - Sine and cosine functions have different frequencies. By using them alternately, you introduce a mix of high-frequency (sine) and low-frequency (cosine)components into the positional encoding.\n",
        "  - The alternating pattern allows the model to capture different aspects of positional information. For example, the model can learn to associate even-indexed columns (sine) with fine-grained details or rapid changes in position, while odd-indexed columns (cosine) may be associated with broader trends or slower changes.\n",
        "  - Using sine and cosine functions in alternating columns also creates an orthogonal encoding. This orthogonality helps ensure that different positional embeddings are not highly correlated, allowing the model to better distinguish between different positions in the sequence."
      ],
      "metadata": {
        "id": "f23Y9VX3pfyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, d_model, max_len=512):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "\n",
        "    # Initialize positional encodings tensor with all 0s\n",
        "    self.encoding = torch.zeros(\n",
        "      max_len, # maximum length of sequences that the positional encoding will be applied to\n",
        "      d_model # dimensionality of the input embeddings (embedding space), e.g., 256\n",
        "    )\n",
        "\n",
        "    # Create a tensor position containing values from 0 to max_len - 1.\n",
        "    position = torch.arange(0, max_len).unsqueeze(1).float() # unsqueeze(1) adds a new dimension to make it a column vector\n",
        "\n",
        "    # Generates a tensor div_term containing exponential values\n",
        "    # It involves using exponential and logarithmic operations to create a set of values that will be used in the positional encoding formula\n",
        "    # The div_term tensor contains values that will be used in the positional encoding formula to introduce varying frequencies of positional information\n",
        "    div_term = torch.exp( # Computes the exponential function (base e) element-wise on the tensor resulting from the below operations.\n",
        "      torch.arange(\n",
        "        0, d_model, # 2 Generates a 1-dimensional tensor containing values from 0 to d_model - 2 with a step size of 2.\n",
        "      ).float() * -( # negative sign is applied because the values will be used with the torch.exp function, and the exponential of a negative value is the reciprocal of the exponential of the positive value.\n",
        "        torch.log(torch.tensor(10000.0)) # Calculates the natural logarithm of 10000.0\n",
        "        / d_model # Divides the logarithm by d_model, and negates the result (- above)\n",
        "      )\n",
        "    )\n",
        "\n",
        "    # Calculate sinusoidal positional encoding\n",
        "    self.encoding[:, 0::2] = torch.sin(position * div_term) # computes the sine of the product of position and div_term for elements in even-indexed columns\n",
        "    self.encoding[:, 1::2] = torch.cos(position * div_term) # cosine of the product of position and div_term for elements in odd-indexed column\n",
        "    self.encoding = self.encoding.unsqueeze(0)  # After calculating sine and cosine values for alternating columns, the entire tensor gets a new dimension at the beginning so it has shape: (1, max_len, d_model)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Add positional encoding to the input tensor (x)\n",
        "    # self.encoding[:, : x.size(1)] = tensor containing positional encoding values for each position in the sequence up to the length of the input x\n",
        "    return x + self.encoding[:, : x.size(1)].detach() # detach means create a copy without gradients"
      ],
      "metadata": {
        "id": "qCM67Pgqph_1"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder and Decoder Stacks\n",
        "- Transformers consist of multiple layers of encoders and decoders. The encoder processes the input sequence, while the decoder generates the output sequence.\n",
        "- Each layer in the encoder and decoder contains a self-attention mechanism and feedforward neural network, enabling the model to learn hierarchical representations.\n",
        "- Encoder perspective\n",
        "  - SelfAttention and MultiHeadAttention: These components contribute to the encoder's self-attention mechanism. In the context of the encoder, the attention mechanism allows each position in the input sequence to focus on relevant positions within the same sequence.\n",
        "  - PositionalEncoding: It adds positional information to the input embeddings. In the encoder, this helps the model consider the order of the input sequence, as transformers do not inherently understand the order of tokens.\n",
        "  - TransformerBlock: Represents a single block in the encoder stack. It typically includes self-attention, normalization, feedforward processing, and skip connections. When stacked, multiple TransformerBlock instances create the encoder layers.\n",
        "- Decoder perspective\n",
        "  - Decoders do things such as handling the end token, maintaining hidden states across time steps, etc.\n",
        "- The encoder and decoder architectures are often instantiated separately and then combined. The decoder usually includes an additional attention mechanism that attends to the encoder's output."
      ],
      "metadata": {
        "id": "6f8MvU6zpiXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, embed_size, heads):\n",
        "    super(TransformerBlock, self).__init__()\n",
        "\n",
        "    # Instantiate multi-head attention mechanism\n",
        "    self.attention = MultiHeadAttention(embed_size, heads)\n",
        "\n",
        "    # Feedforward neural network\n",
        "    self.feedforward = nn.Sequential(\n",
        "      nn.Linear(embed_size, 4 * embed_size), # input = embed_size; output = 4*embed_size\n",
        "      nn.ReLU(), # introduce non-linearity\n",
        "      nn.Linear(4 * embed_size, embed_size), # output = embed_size\n",
        "    )\n",
        "\n",
        "    # Layer normalization\n",
        "    # normalizes values across the feature dimension (along each feature or channel)\n",
        "    # independently for each example in the batch\n",
        "    # helps stabilize training by reducing the internal covariate shift\n",
        "    # which is from the change in the distribution of network activtions due to parameter updates during training\n",
        "    self.norm1 = nn.LayerNorm(embed_size) # normalize outputs of self-attention\n",
        "    self.norm2 = nn.LayerNorm(embed_size) # normalizeoutputs of the feedforward NN\n",
        "\n",
        "    # Dropout for regularization\n",
        "    # sets a fraction of input units to 0 during training\n",
        "    # helps with overfitting\n",
        "    self.dropout = nn.Dropout(0.1) # dropout rate = 0.1\n",
        "\n",
        "  def forward(self, value, key, query, mask):\n",
        "    # Apply multi-head attention\n",
        "    # output 'attention' = (batch_size, query_len, self.heads*self.head_dim)\n",
        "    attention = self.attention(value, key, query, mask)\n",
        "\n",
        "    # Add skip connection (aka residual connection)\n",
        "    # attention + query = skip connection\n",
        "    # allows the model to retain information from the original input instead of only the output\n",
        "    # skip connections address the vanishing gradient problem during training (lets you train deeper networks)\n",
        "    # also facilitates the learning of identity mappings (allowing network to learn to only make necessary modifications to the input)\n",
        "    x = self.norm1( # normalize the folowing\n",
        "      attention + # attention tensor\n",
        "      query # original input tensor\n",
        "    ) # the element-wise addition creates a shortcut connection that directly passes the original input info to the next layer\n",
        "    x = self.dropout(x) # apply dropout\n",
        "\n",
        "    # Feedforward (2 linears layers with ReLU in between)\n",
        "    forward = self.feedforward(x)\n",
        "\n",
        "    # Add another skip connection, this time to the output from the feedforward NN\n",
        "    out = self.norm2(forward + x) # normalize the result of the skip connection\n",
        "    out = self.dropout(out) # apply dropout\n",
        "    return out # dimensions = (batch_size, query_len, embed_size)"
      ],
      "metadata": {
        "id": "4MIBT-DGpk93"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self, embed_size, heads):\n",
        "    super(DecoderBlock, self).__init__()\n",
        "\n",
        "    # Self Attention block -- dependencies within the target sequence\n",
        "    # Handle the self-attention mechanism within the decoder block\n",
        "    # Allows the decoder to attend to different positions within the target sequence\n",
        "    self.self_attention = MultiHeadAttention(embed_size, heads)\n",
        "\n",
        "    # Encoder-Decoder Attention block -- incorporates ino from the sourcesequence into the decoding process\n",
        "    # Used for attenting to the encoder's output from the source sequence\n",
        "    # Lets the decoder consider relevant information from the source sequence while generating the target sequence\n",
        "    # The attention scores are calculated based on the relationship between the target and source sequences\n",
        "    self.encoder_attention = MultiHeadAttention(embed_size, heads)\n",
        "\n",
        "    # Typical FF Network\n",
        "    self.feedforward = nn.Sequential(\n",
        "      nn.Linear(embed_size, 4 * embed_size), # feature expansion (4 times)\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(4 * embed_size, embed_size), # go back to original dimensions\n",
        "    )\n",
        "\n",
        "    # Normalization and dropout\n",
        "    self.norm1 = nn.LayerNorm(embed_size) # normalize output of self-attention mechanism\n",
        "    self.norm2 = nn.LayerNorm(embed_size) # normalize output of the first skip connection\n",
        "    self.norm3 = nn.LayerNorm(embed_size) # normalize output of the second skip connection\n",
        "    self.dropout = nn.Dropout(0.1) # dropout\n",
        "\n",
        "  def forward(self, target, source, target_mask, source_mask):\n",
        "    # Self-Attention Block\n",
        "    # Apply multi-headed self attention to compute attention scores, apply softmax, produce attention-weighted output\n",
        "    # Apply dropout to the attention output, add skip connection, and normalize\n",
        "    attention_output = self.self_attention(target, target, target, target_mask) # targets = q,k,v, plus optional mask\n",
        "    x = self.norm1(target + self.dropout(attention_output))\n",
        "\n",
        "    # Encoder-Decoder Attention Block\n",
        "\n",
        "    # Apply multi-headed self attention to compute attention scores between the current decoder state (x) and the encoder outputs (source) using the provided mask\n",
        "    # Apply dropout to the output, add skip connection, and normalize\n",
        "    encoder_attention_output = self.encoder_attention(x, source, source, source_mask) # x = queries from decoder block; source = keys and values; source_mask = optional\n",
        "    x = self.norm2(x + self.dropout(encoder_attention_output))\n",
        "\n",
        "    # Feedforward Block\n",
        "    forward_output = self.feedforward(x) # linear layer, ReLU, linear layer\n",
        "    x = self.norm3(x + self.dropout(forward_output)) # apply drpout, add skip connection, normalize\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "fzyAvrslT0Zt"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "  def __init__(self, embed_size, heads, num_layers):\n",
        "    super(TransformerDecoder, self).__init__()\n",
        "\n",
        "    # nn.ModuleList = container model that holds multiple instances of DecoderBlock\n",
        "    self.decoder_blocks = nn.ModuleList([\n",
        "      DecoderBlock(embed_size, heads) # for each iteration, a new DecoderBlock is created\n",
        "      for _ in range(num_layers) # run num_layers times\n",
        "    ])\n",
        "\n",
        "  def forward(self, target, source, target_mask, source_mask):\n",
        "    # By applying each DecoderBlock successively,\n",
        "    # it allows the input sequence to undergo multiple transformations,\n",
        "    # capturing complex dependencies and patterns in the decoding process\n",
        "    for decoder_block in self.decoder_blocks:\n",
        "      # for each iteration, the target sequence is updated as it passes through the DecoderBlock\n",
        "      target = decoder_block( # perform self-attention, FF processing, normalization\n",
        "        target, # input sequence to the decoder\n",
        "        source, # source sequence or encoder output\n",
        "        target_mask, # mask certain positions, e.g., helps prevent attending to  future positions in the target sequence during trainging\n",
        "        source_mask # mask certain positions\n",
        "      )\n",
        "    return target"
      ],
      "metadata": {
        "id": "H7J7gdhEUDAg"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feedforward Networks\n",
        "- Transformers include feedforward neural networks within each layer to further capture complex patterns and relationships."
      ],
      "metadata": {
        "id": "TDpLZEu1plMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "    super(FeedForward, self).__init__()\n",
        "\n",
        "    # Two linear layers with ReLU activation in between\n",
        "    self.linear1 = nn.Linear(\n",
        "      d_model, # input dimensionality of the FF NN\n",
        "      d_ff # hidden dimensionality of the FF NN\n",
        "    )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(d_ff, d_model) # go back to input dimensionality\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Apply feedforward neural network\n",
        "    x = self.linear1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.linear2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "vRhpeviTpm6S"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalization and Residual Connections\n",
        "- Layer normalization and residual connections are used to stabilize and speed up training. Residual connections enable the model to directly learn the residual (difference) between the input and output of a layer."
      ],
      "metadata": {
        "id": "DxbgH3twpnQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AddNorm(nn.Module):\n",
        "  def __init__(self, normalized_shape, dropout=0.1):\n",
        "    super(AddNorm, self).__init__()\n",
        "\n",
        "    # Layer normalization with dropout\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.norm = nn.LayerNorm(normalized_shape) # normalized_shape = shape of nprmalized layer (dimensionality of input embeddings or intermediate representations)\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    # Usually this is done to normalize intermediate representations\n",
        "    residual = x + self.dropout(y) # Add skip-connection: element-wise addition of 2 tensors (e.g., adding input tensor to the output of a sub-layer)\n",
        "    return self.norm(residual) # Applies normalization to the residual independently for each example in the batch"
      ],
      "metadata": {
        "id": "J1nkDvrZpoB0"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch's version (according to ChatGPT)\n",
        "Again, there may be errors in this because ChatGPT tends to miss things."
      ],
      "metadata": {
        "id": "VDUAP0IkY_Le"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Input and Target"
      ],
      "metadata": {
        "id": "jqEtYvM2a-Wa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# assuming we are doing a translation task\n",
        "input_sequence = [\"<START>\", \"I\", \"love\", \"transformers\", \"<END>\"]\n",
        "target_sequence = [\"<START>\", \"J'aime\", \"les\", \"transformateurs\", \"<END>\"]\n",
        "input_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT2i838Bd9a-",
        "outputId": "d4e950cb-ccc0-403e-b7c5-1365fd4b3263"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<START>', 'I', 'love', 'transformers', '<END>']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess\n",
        "vocab = {\"<PAD>\": 0, \"<START>\": 1, \"<END>\": 2, \"I\": 3, \"love\": 4, \"transformers\": 5, \"J'aime\": 6, \"les\": 7, \"transformateurs\": 8}\n",
        "word_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
        "word_to_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6bQBKdEeFq8",
        "outputId": "015a4054-6337-4730-c54e-a260cad995e3"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<PAD>': 0,\n",
              " '<START>': 1,\n",
              " '<END>': 2,\n",
              " 'I': 3,\n",
              " 'love': 4,\n",
              " 'transformers': 5,\n",
              " \"J'aime\": 6,\n",
              " 'les': 7,\n",
              " 'transformateurs': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert input_sequence and target_sequence to numeric indices\n",
        "input_sequence_numeric = [word_to_index[word] for word in input_sequence]\n",
        "target_sequence_numeric = [word_to_index[word] for word in target_sequence]\n",
        "input_sequence_numeric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxOlb8jLf4vs",
        "outputId": "c1cfa78f-fadc-499b-c1ff-298247390aac"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3, 4, 5, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define word embeddings\n",
        "embedding_dim = 8\n",
        "embedding = nn.Embedding(len(vocab), embedding_dim)\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IskFp7oef8tR",
        "outputId": "3da37c06-78ff-4270-9f8a-fcea89ccf9c9"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(9, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert numeric indices to embeddings\n",
        "input_sequence_embeddings = embedding(torch.tensor(input_sequence_numeric))\n",
        "target_sequence_embeddings = embedding(torch.tensor(target_sequence_numeric))\n",
        "input_sequence_embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcQ8sABieqvg",
        "outputId": "02301159-a2bd-474e-a660-484f22325407"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3097, -0.3957,  0.8034, -0.6216, -0.5920, -0.0631, -0.8286,  0.3309],\n",
              "        [-1.4181,  0.8963,  0.0499,  2.2667,  1.1790, -0.4345, -1.3864, -1.2862],\n",
              "        [-0.8371, -0.9224,  1.8113,  0.1606,  0.3672,  0.1754,  1.3852, -0.4459],\n",
              "        [-1.2024,  0.7078, -1.0759,  0.5357,  1.1754,  0.5612, -0.4527, -0.7718],\n",
              "        [ 0.0349,  0.3211,  1.5736, -0.8455,  1.3123,  0.6872, -1.0892, -0.3553]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpose to get the desired dimensions (seq_len, batch_size, embedding_dim)\n",
        "input_sequence_embeddings = input_sequence_embeddings.unsqueeze(1).transpose(0, 1)\n",
        "target_sequence_embeddings = target_sequence_embeddings.unsqueeze(1).transpose(0, 1)\n",
        "input_sequence_embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-aQgAVtZBLS",
        "outputId": "15b35847-88a3-4c01-f43e-c7bbaaa1908c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.3097, -0.3957,  0.8034, -0.6216, -0.5920, -0.0631, -0.8286,\n",
              "           0.3309],\n",
              "         [-1.4181,  0.8963,  0.0499,  2.2667,  1.1790, -0.4345, -1.3864,\n",
              "          -1.2862],\n",
              "         [-0.8371, -0.9224,  1.8113,  0.1606,  0.3672,  0.1754,  1.3852,\n",
              "          -0.4459],\n",
              "         [-1.2024,  0.7078, -1.0759,  0.5357,  1.1754,  0.5612, -0.4527,\n",
              "          -0.7718],\n",
              "         [ 0.0349,  0.3211,  1.5736, -0.8455,  1.3123,  0.6872, -1.0892,\n",
              "          -0.3553]]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the dimensions\n",
        "print(\"Input Sequence Embeddings Dimensions:\", input_sequence_embeddings.size())\n",
        "print(\"Target Sequence Embeddings Dimensions:\", target_sequence_embeddings.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFEbPhnygD6L",
        "outputId": "d116e369-0cca-442d-84ea-3b6be11e6600"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sequence Embeddings Dimensions: torch.Size([1, 5, 8])\n",
            "Target Sequence Embeddings Dimensions: torch.Size([1, 5, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoder"
      ],
      "metadata": {
        "id": "xAN7ixJAbADD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, num_layers, num_heads):\n",
        "    super(TransformerEncoder, self).__init__()\n",
        "\n",
        "    # Positional Encoding\n",
        "    self.positional_encoding = nn.Embedding(100, input_dim)  # Assuming maximum sequence length is 100\n",
        "\n",
        "    # Transformer Encoder Layer\n",
        "    encoder_layers = nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads)\n",
        "    self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
        "\n",
        "  def forward(self, src):\n",
        "    src = src + self.positional_encoding(torch.arange(src.size(0)).unsqueeze(1).to(src.device))\n",
        "    encoder_output = self.transformer_encoder(src)\n",
        "    return encoder_output"
      ],
      "metadata": {
        "id": "lihIvTxUZYAk"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# positional encoding\n",
        "positional_encoding = nn.Embedding(100, embedding_dim)\n",
        "positional_encoding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDcfElyBbkTY",
        "outputId": "28633526-37fc-464d-baa2-be3675a713f6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(100, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder layers\n",
        "num_heads = 4\n",
        "encoder_layers = nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=num_heads)\n",
        "encoder_layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ8Q6xDBbr7_",
        "outputId": "437e93fc-6100-4f3d-f081-7435c3bf12ac"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerEncoderLayer(\n",
              "  (self_attn): MultiheadAttention(\n",
              "    (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
              "  )\n",
              "  (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
              "  (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
              "  (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
              "  (dropout1): Dropout(p=0.1, inplace=False)\n",
              "  (dropout2): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# complete encoder\n",
        "num_layers = 2\n",
        "transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
        "transformer_encoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORlf2saVb1uW",
        "outputId": "cf9996b5-d9c2-40de-f3d7-a3088c198e68"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerEncoder(\n",
              "  (layers): ModuleList(\n",
              "    (0-1): 2 x TransformerEncoderLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
              "      )\n",
              "      (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
              "      (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass part 1\n",
        "hidden_dim = 512\n",
        "src = input_sequence_embeddings # for the first pass\n",
        "\n",
        "src = src + positional_encoding(torch.arange(src.size(0)).unsqueeze(1).to(src.device))\n",
        "src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ0mxuRjcB7q",
        "outputId": "f1f9538f-df59-45ec-8b07-d58f8a3beec0"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.7668, -0.4980,  0.2043, -0.1445,  0.1342,  0.0281, -1.2176,\n",
              "           0.8588],\n",
              "         [-2.8751,  0.7939, -0.5492,  2.7438,  1.9051, -0.3433, -1.7754,\n",
              "          -0.7583],\n",
              "         [-2.2942, -1.0247,  1.2122,  0.6376,  1.0934,  0.2666,  0.9961,\n",
              "           0.0821],\n",
              "         [-2.6595,  0.6055, -1.6750,  1.0127,  1.9015,  0.6523, -0.8418,\n",
              "          -0.2439],\n",
              "         [-1.4221,  0.2188,  0.9744, -0.3684,  2.0385,  0.7783, -1.4782,\n",
              "           0.1726]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass part 2\n",
        "encoder_output = transformer_encoder(src)\n",
        "encoder_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGP9PmPKcJZt",
        "outputId": "978cdcb8-4328-4ccf-c558-0b13a716fe5f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-2.4061,  0.7606,  0.1984,  0.2167,  1.0792, -0.3177,  0.5261,\n",
              "          -0.0572],\n",
              "         [-1.3867, -0.6685, -0.2469,  1.8655,  1.2047, -0.1778,  0.1694,\n",
              "          -0.7598],\n",
              "         [-1.9598, -0.4565,  0.8358,  0.5780,  0.2689,  1.1073,  0.6935,\n",
              "          -1.0671],\n",
              "         [-1.6918,  0.2978, -0.6707,  0.9531,  1.5362,  0.6629, -0.1564,\n",
              "          -0.9312],\n",
              "         [-1.1546,  0.8222,  0.3789, -0.1069,  1.9005, -0.5666,  0.1023,\n",
              "          -1.3757]]], grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decoder"
      ],
      "metadata": {
        "id": "fbG4kHtUbIgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, num_layers, num_heads):\n",
        "    super(TransformerDecoder, self).__init__()\n",
        "\n",
        "    # Positional Encoding\n",
        "    self.positional_encoding = nn.Embedding(100, input_dim)  # Assuming maximum sequence length is 100\n",
        "\n",
        "    # Transformer Decoder Layer\n",
        "    decoder_layers = nn.TransformerDecoderLayer(d_model=input_dim, nhead=num_heads)\n",
        "    self.transformer_decoder = nn.TransformerDecoder(decoder_layers, num_layers=num_layers)\n",
        "\n",
        "  def forward(self, tgt, memory):\n",
        "    tgt = tgt + self.positional_encoding(torch.arange(tgt.size(0)).unsqueeze(1).to(tgt.device))\n",
        "    decoder_output = self.transformer_decoder(tgt, memory)\n",
        "    return decoder_output"
      ],
      "metadata": {
        "id": "_3IvNLGtZ_Qd"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# same type of positional encoding as before\n",
        "positional_encoding = nn.Embedding(100, embedding_dim)\n",
        "positional_encoding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebXYNCKQaJgl",
        "outputId": "21a715d3-d274-4d99-c6d3-d49898c95f63"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(100, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder layers (input_dim and num_heads were defined above)\n",
        "decoder_layers = nn.TransformerDecoderLayer(d_model=embedding_dim, nhead=num_heads)\n",
        "decoder_layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlpBmOoNc6_O",
        "outputId": "b80eed82-87a8-43f1-9672-43f6342e6f60"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerDecoderLayer(\n",
              "  (self_attn): MultiheadAttention(\n",
              "    (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
              "  )\n",
              "  (multihead_attn): MultiheadAttention(\n",
              "    (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
              "  )\n",
              "  (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
              "  (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
              "  (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
              "  (norm3): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
              "  (dropout1): Dropout(p=0.1, inplace=False)\n",
              "  (dropout2): Dropout(p=0.1, inplace=False)\n",
              "  (dropout3): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# complete decoder\n",
        "transformer_decoder = nn.TransformerDecoder(decoder_layers, num_layers=num_layers)\n",
        "transformer_decoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WijLwQ2dGbZ",
        "outputId": "ab66d55b-e630-4b3f-8a8a-3120758b9768"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerDecoder(\n",
              "  (layers): ModuleList(\n",
              "    (0-1): 2 x TransformerDecoderLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
              "      )\n",
              "      (multihead_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
              "      )\n",
              "      (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
              "      (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm3): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      (dropout3): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass part 1\n",
        "tgt = target_sequence_embeddings\n",
        "\n",
        "# add positional encoding to tgt\n",
        "tgt = tgt + positional_encoding(torch.arange(tgt.size(0)).unsqueeze(1).to(tgt.device))\n",
        "tgt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrJfdIHIdOHO",
        "outputId": "1dbcc9be-1718-4251-f0a0-4436a3aa8e04"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.4234,  1.0549,  1.4027, -1.7579,  0.4894,  0.4945, -1.3520,\n",
              "           0.3444],\n",
              "         [ 0.8785,  1.6816,  0.6080, -1.2786,  1.2785, -0.5866, -0.1851,\n",
              "           1.7126],\n",
              "         [-1.7764,  1.9386,  1.3839, -1.1077,  1.7221,  1.1408,  0.5435,\n",
              "          -0.4367],\n",
              "         [ 0.5479,  2.2033,  1.0041, -0.9579,  1.3463,  1.8307, -0.5247,\n",
              "          -0.2901],\n",
              "         [ 0.7681,  1.7717,  2.1729, -1.9818,  2.3937,  1.2447, -1.6126,\n",
              "          -0.3418]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass part 2\n",
        "decoder_output = transformer_decoder(tgt, memory=encoder_output)\n",
        "decoder_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvgmLT2xdTCR",
        "outputId": "1a345201-5934-46f7-dc5b-9680cac1b1f2"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.6662,  1.9303,  0.2898, -1.6784,  0.7114, -0.4760,  0.2527,\n",
              "          -0.3635],\n",
              "         [-0.0326, -0.1332, -0.3087, -1.9751,  1.9234, -0.1831,  0.3547,\n",
              "           0.3547],\n",
              "         [-0.9252,  1.7326, -0.3209, -1.5991,  0.9040,  0.4502,  0.3445,\n",
              "          -0.5861],\n",
              "         [-0.9603,  1.8655, -0.2763, -0.6974,  0.5581,  0.8802,  0.0260,\n",
              "          -1.3958],\n",
              "         [ 0.0890,  1.7539,  0.2355, -1.3498,  1.2511, -0.3309, -0.8706,\n",
              "          -0.7782]]], grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Complete Transformer Model"
      ],
      "metadata": {
        "id": "SqLpnEh_bNaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerModel(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, num_layers, num_heads):\n",
        "    super(TransformerModel, self).__init__()\n",
        "\n",
        "    # Transformer Encoder\n",
        "    self.encoder = TransformerEncoder(input_dim, hidden_dim, num_layers, num_heads)\n",
        "\n",
        "    # Transformer Decoder\n",
        "    self.decoder = TransformerDecoder(input_dim, hidden_dim, num_layers, num_heads)\n",
        "\n",
        "  def forward(self, src, tgt):\n",
        "    encoder_output = self.encoder(src)\n",
        "    decoder_output = self.decoder(tgt, encoder_output)\n",
        "    return decoder_output"
      ],
      "metadata": {
        "id": "ML8gBvIGaN9a"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_model = TransformerModel(embedding_dim, hidden_dim, num_layers, num_heads)\n",
        "transformer_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osThlySbbVK8",
        "outputId": "6109dd39-dd75-4123-e657-6cf0a982f21b"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerModel(\n",
              "  (encoder): TransformerEncoder(\n",
              "    (positional_encoding): Embedding(100, 8)\n",
              "    (transformer_encoder): TransformerEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-1): 2 x TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
              "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): TransformerDecoder(\n",
              "    (positional_encoding): Embedding(100, 8)\n",
              "    (transformer_decoder): TransformerDecoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-1): 2 x TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
              "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = transformer_model(input_sequence_embeddings, target_sequence_embeddings)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN9UTEK1rt08",
        "outputId": "46e8571c-eb2b-4d80-e7c9-93f528644ef6"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.0572,  0.0405, -0.2031,  0.1402, -1.6413,  1.7765, -0.0395,\n",
              "           0.9839],\n",
              "         [-0.9044, -0.0223, -0.8285,  0.2424, -1.6464,  0.5541,  1.4155,\n",
              "           1.1896],\n",
              "         [-1.6538, -0.8957, -0.2331,  0.5674, -0.8157,  1.4619,  0.9472,\n",
              "           0.6217],\n",
              "         [-1.4123, -0.4543, -0.5179,  1.0081, -1.3601,  0.8673,  1.2223,\n",
              "           0.6469],\n",
              "         [-1.6532, -0.4613,  0.5788, -0.0962, -0.7191,  1.5789, -0.4512,\n",
              "           1.2232]]], grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notes from Jay Alammar's [Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)"
      ],
      "metadata": {
        "id": "3oTJNWHqzaKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer\n",
        "- RNNs\n",
        "  - Input our sequence or the sentence in a continuous manner, one word at a time, to generate word embeddings\n",
        "  - Every word depends on the previous word, and its hidden state acts accordingly, so we have to feed it in one step at a time\n",
        "  - Can include attention (but not always used)\n",
        "- Transformer (not an RNN)\n",
        "  - A model that uses attention to boost the speed with which these models can be trained\n",
        "  - Allows the input sequence to be passed parallelly so that GPU can be used effectively and the speed of training can also be increased\n",
        "  - Based on the multi-headed attention layer, so it easily overcomes the vanishing gradient issue\n",
        "- Transformer and attention\n",
        "  - Can pass all the word embeddings (?) (and corresponding hidden states) of a sentence to a decoder simultaneously\n",
        "  - Attention vectors are generated for every word in the documents to represent how much each word is contextually related to every word in the same document\n",
        "  - Unlike the case of the RNN, each of these attention vectors is independent of one another --> parallelization is possible) we can apply parallelization\n",
        "- How it works\n",
        "  - Input --> stack of encoders --> stack of decoders --> output\n",
        "  - Encoders are all identical in structure, but don't share weights. 2 layers\n",
        "    - Self-attention = helps the encoder look at other words in the input sentence as it encodes a specific word. Has dependencies (for each word in the sequence).\n",
        "    - Feed Forward NN = the outputs of the self-attention layer are fed to a feed-forward neural network. The exact same feed-forward network is independently applied to each position. No dependecies, so can be parallelized\n",
        "  - Decoder -- 3 layers.\n",
        "    - Self-attention\n",
        "    - Encoder-Decoder Attention -- helps the decoder focus on relevant parts of the input sentence\n",
        "    - Feed Forward NN\n",
        "  - Step 1. Embedding\n",
        "  - Step 2. Encoders\n",
        "    - Each encoder receives a list of vectors as an input (each vector is one word's embedding)\n",
        "    - It processes the vectors in the self-attention layer\n",
        "    - Layer normalization (adding embeddings + self-attention outputs)\n",
        "    - Feed forward NN\n",
        "    - Layer normalization (add and normalize)\n",
        "    - Sends the outputs to the next encoder (self-attention, feed forward NN)\n",
        "  - Step 3. Decoders\n",
        "    - The output of the top encoder is transformed into a set of attention vectors (K and V) and fed to the bottom layer of the decoder\n",
        "    - Each decoder has 3 steps:\n",
        "    - Self attention\n",
        "    - Encoder-Decoder attention\n",
        "    - Feed Forward NN\n",
        "  - Step 4. Final Linear and Softmax layer\n",
        "    - Output of decoder = vector of floats\n",
        "    - The Linear layer is a simple fully connected neural network that projects the vector produced by the stack of decoders, into a much, much larger vector called a logits vector -- where each cell corresponding to the score of a unique word\n",
        "    - The softmax layer then turns those scores into probabilities (all positive, all add up to 1.0). The cell with the highest probability is chosen, and the word associated with it is produced as the output for this time step\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- Self Attention\n",
        "  - For each word's embedding, create 3 vectors (by multiplying the embedding by three weight matrices that we trained during the training process):\n",
        "  - Query vector: embedding * query weight matrix\n",
        "  - Key vector: embedding * key weight matrix\n",
        "  - Value vector: embedding * value weight matrix\n",
        "- Calculate a score\n",
        "  - Score each word of the input sentence against the word you're looking at\n",
        "  - Determines how much focus to place on other parts of the input sentence as we encode a word at a certain position\n",
        "  - The score (for each word in the sentence) is calculated by taking the dot product of the query vector with the key vector of the respective word we’re scoring\n",
        "- Divide the scores (for each word in the sentence) by 8\n",
        "  - 8 is the square root of the dimension of the key vectors used in the attention paper – 64)\n",
        "  - This leads to having more stable gradients\n",
        "- Pass the result through a softmax\n",
        "  - Normalizes the scores so they’re all positive and add up to 1\n",
        "  - This softmax score determines how much each word will be expressed at this position\n",
        "  - Clearly the word at this position will have the highest softmax score, but sometimes it’s useful to attend to another word that is relevant to the current word\n",
        "- Multiply each value vector by the softmax score (in preparation to sum them up)\n",
        "  - The intuition here is to keep intact the values of the word(s) we want to focus on, and drown-out irrelevant words (by multiplying them by tiny numbers like 0.001, for example)\n",
        "- Sum up the weighted value vectors\n",
        "  - This produces the output of the self-attention layer at this position (for the first word)\n",
        "  - The resulting vector is one we can send along to the feed-forward neural network\n",
        "- In the actual implementation, however, this calculation is done in matrix form for faster processing\n",
        "  - Every row in the X matrix corresponds to a word in the input sentence\n",
        "  - Since we’re dealing with matrices, we can condense steps two through six in one formula to calculate the outputs of the self-attention layer\n",
        "- In the decoder, the self-attention layer is only allowed to attend to earlier positions in the output sequence. This is done by masking future positions (setting them to -inf) before the softmax step in the self-attention calculation\n",
        "\n",
        "\n",
        "- Multi-headed attention\n",
        "  - Improves the performance of the attention layer in two ways:\n",
        "  - It expands the model’s ability to focus on different positions\n",
        "  - It gives the attention layer multiple “representation subspaces”\n",
        "  - In multi-headed attention we have not only one, but multiple sets of Query/Key/Value weight matrices (the Transformer uses eight attention heads, so we end up with eight sets for each encoder/decoder). Each of these sets is randomly initialized\n",
        "  - Do the same self-attention calculation we outlined above eight different times with different weight matrices -- we end up with eight different Z matrices\n",
        "  - Concatatenate all the attention heads (matrices)\n",
        "  - Multiply them by an additional weights matrix WO that was trained jointly with the model\n",
        "  - The result = Z matrix that captures information from all the attention heads. THis is sent to the feed forward NN\n",
        "  - After training, each set is used to project the input embeddings (or vectors from lower encoders/decoders) into a different representation subspace\n",
        "\n",
        "\n",
        "- The transformer adds a vector to each input embedding to account for the order of words in the input sentence\n",
        "  - These vectors follow a specific pattern that the model learns, which helps it determine the position of each word, or the distance between different words in the sequence\n",
        "  - The intuition here is that adding these values to the embeddings provides meaningful distances between the embedding vectors once they’re projected into Q/K/V vectors and during dot-product attention\n",
        "  - Embeddings + positional encodings = embeddings with time signal\n",
        "- In the decoder, the “Encoder-Decoder Attention” layer works just like multiheaded self-attention, except it creates its Queries matrix from the layer below it, and takes the Keys and Values matrix from the output of the encoder stack\n",
        "  - K and V are used by each decoder in its \"encoder-decoder attention layer\" (helps the decoder focus on appropriate places in the input sentence)\n",
        "\n"
      ],
      "metadata": {
        "id": "j1mF2EeHIEMs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yIi_m2tX8aY8"
      },
      "execution_count": 82,
      "outputs": []
    }
  ]
}